{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Only focus on model\n- things matter end result: train_test_split portion, dependent variables for prediction (unit price vs total price), model parameters\n- mainly using lightgbm testing different combination\n- result record in [here](https://docs.google.com/spreadsheets/d/1WaLDSYc89plQ_um0mpxMoPjoRlX8iXUhy-nBGzTV6U8/edit?usp=sharing)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#--- import some necessary librairies\n\nimport numpy as np \nimport pandas as pd \nimport re\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\ncolor = sns.color_palette()\nsns.set_style('darkgrid')\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\n\npd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points\nfrom scipy.special import boxcox1p,inv_boxcox1p\nfrom scipy.stats import boxcox_normmax,boxcox\n\nfrom subprocess import check_output\nfrom sklearn.externals import joblib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/house-data/train.csv')\ntest = pd.read_csv('../input/house-data/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"unit_price\"] = train[\"total_price\"]/train[\"building_area\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_building_id = test.building_id.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train.unit_price.values\ny_price = train.total_price.values\n\nall_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['total_price'], axis=1, inplace=True)\nall_data.drop(['unit_price'], axis=1, inplace=True)\n\ndel all_data[\"building_id\"]\nprint(\"all_data size is : {}\".format(all_data.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Deal with missing value & change categorical variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.isnull().sum().sort_values(ascending=False)[:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill in missing value\ndel all_data[\"parking_area\"]\nall_data[\"txn_floor\"] = all_data[\"txn_floor\"].fillna(0)\nall_data[\"parking_price\"] = all_data[\"parking_price\"].fillna(0)\nall_data['village_income_median'] = all_data['village_income_median'].fillna(all_data['village_income_median'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add features [v2]\n\nall_data[\"ratio_floor\"] = all_data[\"txn_floor\"]/all_data[\"total_floor\"]\nall_data[\"top_floor\"] = np.where(all_data[\"txn_floor\"]==all_data[\"total_floor\"],1,0)\nall_data[\"perc_land\"] =  all_data[\"land_area\"]/all_data[\"building_area\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add features [v3]\nmain_col = [\"village_income_median\", \"town_population\", \"town_area\",\n            \"city\", \"town\", \"village\",\"land_area\", \"building_area\"] \ninteract_col = [col for col in all_data.columns if re.search(\"[a-zA-Z]_rate$\", col, re.IGNORECASE)!=None]\n\nfor m_col in main_col:\n    for i_col in interact_col:\n        all_data[m_col+\"_\"+i_col+\"_IT\"] = all_data[m_col]*all_data[i_col]  \n        \nfor col in interact_col:\n    all_data[col+\"_s\"] = all_data[col]**2\n    \n\nall_data[\"ratio_parking_price\"] = all_data[\"parking_price\"]/all_data[\"village_income_median\"]\nall_data[\"good_factor\"] = all_data[\"marriage_rate\"]+all_data[\"master_rate\"]+all_data[\"bachelor_rate\"]\nall_data[\"good_factor\"+\"_s\"] = all_data[\"good_factor\"]**2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = all_data[:len(train)]\ntest = all_data[len(train):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.model_selection import GridSearchCV\nfrom mlxtend.classifier import StackingClassifier\nfrom sklearn.svm import SVR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#--- Evaluation metric\n\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef MAPE(y, y_pred):\n    return sum(abs(y_pred-y)/y)/len(y)\n\ndef Score(y, y_pred):\n    y=np.expm1(y)\n    y_pred=np.expm1(y_pred)\n    hit_rate = np.around(np.sum(np.where(abs((y_pred-y)/y)<.1,1,0))/len(y),decimals=4)*10000\n    MAPE = 1-np.sum(abs((y_pred-y)/y))/len(y)\n    return hit_rate+MAPE\n\ndef Score_MAPE(y, y_pred):\n    y=np.expm1(y)\n    y_pred=np.expm1(y_pred)\n    MAPE = 1-np.sum(abs((y_pred-y)/y))/len(y)\n    return MAPE\n\n# archive\ndef Score_type(y, y_pred, h_type):\n    y = np.expm1(y)\n    y_pred = np.where(h_type>0,np.expm1(y_pred),0)\n    hit_rate = np.around(np.sum(np.where(abs((y_pred-y)/y)<.1,1,0))/len(y),decimals=4)*10000\n    MAPE = 1-np.sum(abs((y_pred-y)/y))/len(y)\n    return hit_rate+MAPE\n\n# archive\ndef Score_acc(y, y_pred, h_type):\n    y = np.expm1(y)\n    y_pred = np.where(h_type>0,np.expm1(y_pred),0)\n    type_total = sum(np.where(h_type>0,1,0))\n    hit_rate = np.sum(np.where(abs((y_pred-y)/y)<.1,1,0))/type_total\n    return hit_rate#+MAPE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, train_y, valid_y = train_test_split(train, np.log1p(y_train), test_size=0.1, random_state= 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # model 0\n# gbm = lgb.LGBMRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # model 1 \n# gbm = lgb.LGBMRegressor(objective='regression',\n#                         num_leaves=80,\n#                         learning_rate=0.03,\n#                         n_estimators=6769,\n#                        colsample_bytree = 0.6886781648348815,\n#                        max_depth = 18,\n#                        subsample = 0.7241144257909466)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model 2\ngbm = lgb.LGBMRegressor(objective='regression',\n                        metric='mape',\n                        num_leaves=80,\n                        learning_rate=0.03,\n                        n_estimators=6769,\n                       colsample_bytree = 0.6886781648348815,\n                       max_depth = 18,\n                       subsample = 0.7241144257909466)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm.fit(X_train, train_y)\n#y_pred = gbm.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show feature importance\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(gbm, random_state=0).fit(X_valid, valid_y)\neli5.show_weights(perm, feature_names = X_valid.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lgbm inbuilt feature importance\nlgb.plot_importance(xgb, max_num_features=30,figsize=(12,9))\n\nplt.title(\"Featurertances\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Score:\", Score(valid_y, y_pred))\nprint(\"Loss:\", rmsle(valid_y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submit\ny_pred_final = gbm.predict(test)\ny_final = np.expm1(y_pred_final)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission[\"prediction\"] = y_final*test[\"building_area\"]\nsubmission[\"building_id\"] = test_building_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}